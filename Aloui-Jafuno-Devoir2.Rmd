---
title: "Devoir 2"
author: "Aloui Mohamed, Jafuno Douba"
date: "3 décembre 2018"
output: html_document
---

```{r,echo=F}
library("knitr")
body<-read.table("BodyFat.txt",header= TRUE ,sep= ";",row.names=NULL)
body<-body[,-1] #suppression de la colonne X
body$Weight<-body$Weight*0.453 #conversion du poids en kilos 1 Livres = 0.453kg
body$Height<-body$Height*2.54  #conversion 1 pouce=2,54kg
a=length(body[,1])*2/3


#Question 1 
bodyap<-body[c(1:as.integer(a)),]
bodytest<-body[c((as.integer(a)+1):length(body[,1])),]

```

### Question 1


Pour commmencer nous découpons notre jeu de données en un jeu d'apprentissage **bodyap** composé de **168** hommes et un jeu de données test **bodytest** composé de **84** hommes.Nous considérons donc le **modèle 1** linéaire suivant :

$$\text{bodyfat} = \beta_0 + \beta_1\text{Age} + \beta_2\text{Weight}+\beta_3\text{Height}+\beta_4\text{Neck}+\beta_5\text{Abdomen}+\beta_6\text{Hip}+\beta_7\text{Thigh}+\beta_8\text{Knee}$$

  $$\beta_9\text{Anckle}+\beta_{10}\text{Biceps}+\beta_{11}\text{Forearms}+\beta_{12}\text{Wrist}+\varepsilon$$
  
```{r,echo=FALSE}
reg <- lm(bodyfat~., data = bodyap) #modele 1
```
  
### Question 2

Le jeu d'apprentissage comporte beaucoup de variables explicatives. Dans le package leaps, la fonction regsubsets retourne, pour différents critères (bic,  $R^2$, $R^2_a$ (ajusté), Cp de Mallows, etc.), le meilleur modèle, l'analyse de ces graphiques nous permettra de choisir les variables à conserver dans le **modèle 1**.

Voici les 3 Regbusets 




```{r ,fig.height=5, fig.width=10, echo=FALSE}
library(leaps)
choix <- regsubsets(bodyfat~., data = bodyap, nvmax = 14)
par(mfrow = c(1, 3))
plot(choix, scale = "r2",main= 'Regsubsets R^2')
plot(choix, scale = "adjr2",main="Regsubsets R^2_ajusté")
plot(choix, scale = "bic",main="Regsubsets BIC")


```

Pour le premier graphique on cherche donc le modèle qui maximise le coefficient de détermination $R^2$. On retrouve le fait que le coefficient $R^2$ augmente avec le nombre de variables et que pour une comparaison entre modèles emboîtés, On sélectionne toute les variables il n'est pas judicieux de considérer ce critère.

Pour le second graphique le but est de maximiser le coefficient $R^2_a$. Ici, c'est le modèle contenant la constante, les variables, **Age**, **Weight**, **Height**, **Neck**, **Abdomen**, **Hip**, **Tigh**, **Anckle**, **Forearm** et **Wrist**

Pour le troisième graphique on cherche à minimiser le critère BIC. On choisit donc le modèle contenant la constante, les variables **Age**, **Weight**, **Abdomen**, **Forearm** et **Wrist**. 




Au vue des graphiques ci dessus la constante et les variables **Age**, **Weight**, **Abdomen**, **Forearm** et **Wrist**, nous semblent etre les plus pertinentes à l'étude, nous les choisissons donc pour la suite de l'étude.





### Question 3



Etant donné un échanillion (**bodyfat**,**Age**, **Weight**, **Abdomen**, **Forearm**, **Wrist**) Le but de cette étude de notre jeu d'apprentissage cherche précisément à expliquer la variable **bodyfat** à partir des variables explicatives **Age**, **Weight**, **Abdomen**, **Forearm** et **Wrist**

Nous considérons donc le nouveau **modèle 2** de régrésion linéaire suivant:   

$$\text{bodyfat} = \beta_0 + \beta_1\text{Age} + \beta_2\text{Weight}+\beta_3\text{Abdomen}+\beta_4\text{Forearm}+\beta_5\text{Wrist}+\varepsilon$$
Il s'agit d'un modèle de régression multiple où $\varepsilon$ est l'erreur du modèle qui exprime l'information manquante dans l'explication linéaire des valeurs de **bodyfat** à partir des variables explicatives (**Age**, **Weight**, **Abdomen**, **Forearm** et **Wrist**). Les coefficients $\beta_i$ sont les paramètres que nous chercherons à estimer.

```{r,echo=FALSE}

reg1 <- lm(bodyfat~Age+Weight+Abdomen+Forearm+Wrist, data = bodyap) #notre modèle avec les données du jeu d'apprentissage 

```



### Question 4


**Validation du modèle**

**Afin de pouvoir valider le modèle on effectue une analyse des résidus  considérons les 4 graphiques ci dessous créé avec la fonction plot(lm) **


```{r ,fig.height=8, fig.width=8, echo=FALSE}
par(mfrow = c(3, 2))
plot(reg1)


levier <- hatvalues(reg1)
n=168
plot(1:n, levier, xlab = 'Index', ylab = 'Poids h_ii', main = 'Points leviers')
p <- reg1$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
abline(seuil1, 0, lty = 2)
abline(seuil2, 0, lty = 3)
IDlev <- (1:n)[levier>seuil2]
text(IDlev, levier[IDlev], IDlev, pos = 4, col = 'blue')

residus <- rstudent(reg1)
n <- 168
plot(1:n, residus, pch = 16, xlab = 'Index', ylab = 'Residus studentises',ylim=c(-4,4),
     main = 'Valeurs aberrantes')
abline(-2, 0, lty = 2)
abline(2, 0, lty = 2)
IDval.ab <- (1:n)[abs(residus)>2]
text(IDval.ab, residus[IDval.ab], IDval.ab, pos = 4, col = 'blue')
```

**Le premier graphique Residuals vs Fitted**  illustre la dispersion des résidus en fonction des valeurs prédites par le modèle de régression linéaire. Chaque point représente la distance entre la variable réponse et la réponse prédite par le modèle. Ici les résidus forment une bande horizontale approximative autour de la ligne de 0, **la variance des résidus est homogène (donc, ils sont homoscédastiques)**, le modèle est **validé**.

**Le second graphique (Diagramme quantile-quantile (QQplot)** compare la distribution de probabilité des résidus du modèle à une distribution de probabilité de données normales. On voit que la plus part es résidus standardisés se trouvent près de la première bissectrice on pourrait eventuellement retiré des valeurs aberrantes ou des points leviers si il y en a. **Les résidus peuvent être considérés comme normalement distribués**.

**Dans le troisième graphique "Scale-location avec celui des valeurs aberantes"** permet de vérifier si la dispersion des résidus augmente pour une valeur prédite donnée (i.e. si la dispersion des résidus est causée par la variable explicative). **Si la dispersion augmente, la condition de base d'homoscédasticité n'est pas respecté ici elle n'augmente pas elle diminue** de plus ce graphique permet de comparer la racine des résidus studentisés à   $\sqrt(2) = 1.4$   : il y a 4 observations au dessus de ce seuil, donc **4 valeurs aberrantes (53, 81, 119 et 140)**.



**Dans les derniers graphiques Diagramme de résidus vs. influence: Distance de Cook et Points leviers** Si une ou certaines observations sont aberrantes (dont, si elles ont des valeurs très différentes des autres), le modèle peut être mal ajusté en raison de leur influence exagérée sur la calculation du modèle. Si (et seulement si!) ces observations correspondent à des erreurs de mesure ou à des exceptions (à la fois point levier et valeurs abérantes), elles peuvent être retirées du jeu de donnée, observons les. 

- Pour les points leviers (4ème et 5ème graphique) :
    
    - pour le seuil $2p/n = 0.07$ : on observe une valeur au-dessus (poids hii )
     
    - pour le seuil $3p/n = 0.10$ : on voit 4 valeurs au dessus du seuil       
    préoccupant
    
    on en déduit donc qu'il y a **4 points leviers (39,36,41 et 159)** dans le jeu de donnees
    
  
  
- Pour la distance de Cook : le seuil du cours $F_{p,n-p}(0.1) = 0.49$ est proche de 0.5 indiqué sur le 4ème graphique. Il n'y a pas de point qui dépasse la bande de 0.5, donc en terme de distance de Cook, **il n'y a pas d'observations suspectes en effet on a aucun point qui est à la fois un point levier et une valeur aberrante.**

Tout cela montre que **notre modèle est bien valide**

### Question 5

### Masses graisseuses prédites
```{r,echo=FALSE}

a=bodytest$bodyfat


Y2<- predict(reg1, newdata = bodytest) #Question 5.1 Vecteur des valeurs prédites  pour les masses graisseuses de chaque homme grâce au modèle pour les données du jeu test on affiche les 10 premiers 


a=c(Y2[1:10])
a=as.data.frame(a)
rownames(a)=c("1er "," 2ème","3eme "," 4ème","5ème"," 6ème"," 7ème"," 8ème","9ème ","10ème ")
colnames(a)="Masses graisseuses prédites pour les 10 premiers hommes du jeu de test"
kable(a)


```



###Erreurs de prédiction
```{r ,fig.height=2, fig.width=2, echo=FALSE}
Y1<- predict(reg, newdata = bodytest) #valeurs des masses graisseuse prédites par le modele 1 pour le jeu test
Y2<- predict(reg1, newdata = bodytest) #valeurs des masses graisseuse prédites par le modele 2 pour le jeu test
erreur= bodytest$bodyfat-Y2 # #Question 5.2 vecteur contenant les erreurs de prédictions pou chaque individus de notre jeu de test on afiche les 10 premiers 
erreur1=erreur[1:10]
 a= data.frame(erreur1)
colnames(a)<- "Erreurs de prédiction des 10 premiers hommes du jeu de test"
rownames(a)=c("1er "," 2ème","3eme "," 4ème","5ème"," 6ème"," 7ème"," 8ème","9ème ","10ème ")
kable(a)
 
#Calcul des erreur quadratiquee moyenne de prévisons


Y <- bodytest$bodyfat

EQM1 <- sum((Y1- Y)^2/84)

EQM2 <- sum((Y2 - Y)^2/84)

a=c(EQM1,EQM2)
names(a)=c("Modele 1","Modele 2")
a=as.data.frame(a)
colnames(a)="Erreur quadratique moyenne de prévison"
kable(a)

```


Le second modèle, moins lié aux données d'apprentissage, a  une meilleure capacité de prédiction de la masse graisseuse que le premier modèle car son erreur quadratique moyenne de prévison est inférieure à celle du premier.