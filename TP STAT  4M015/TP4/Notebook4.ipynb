{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression simple\n",
    "\n",
    "## Rappel\n",
    "\n",
    "La régression linéaire simple permet de modéliser la relation linéaire entre deux variables quantitatives dans un objectif explicatif et/ou prévisionnel. Nous disposons d'une variable explicative, notée $x$, et une variable à expliquer, notée $y$, liées par le modèle suivant :\n",
    "$$y=\\beta_0+\\beta_1x+\\varepsilon,$$\n",
    "où $\\varepsilon$ est la variable de bruit ou erreur de mesure. Nous supposons que $\\varepsilon$ est une variable aléatoire centrée de variance $\\sigma^2$, et éventuellement de loi normale $\\mathcal N(0,\\sigma^2)$.\n",
    "Nous disposons de $n$ couples $(x_1,y_1),\\dots,(x_n,y_n)$ afin d'estimer les paramètres  inconnus $\\beta_0$ et $\\beta_1$. Notons $X=(x_1,\\dots,x_n)^T$, $A=[\\mathbb 1,X]$ et $Y=(y_1,\\dots,y_n)^T$. L'estimateur $(\\hat\\beta_0,\\hat\\beta_1)$ par la méthode des moindres carrés est donné par \n",
    "$$(\\hat\\beta_0,\\hat\\beta_1)^T=(A^TA)^{-1}A^TY.$$\n",
    "D'après le cours, on a \n",
    "$$\\hat\\beta_0=\\bar Y-\\hat\\beta_1\\bar X,\\qquad\n",
    "\\hat\\beta_1=\\frac{\\mathrm{Cov}(X,Y)}{\\mathrm{Var}(X)}.$$\n",
    "Une fois les paramètres estimés, on obtient la droite de régression\n",
    "$$f(x) = \\hat\\beta_0+\\hat\\beta_1 x,$$\n",
    "ce qui permet  d'effectuer des prévisions pour une nouvelle variable $x^*$ par $$y^P=f(x^*)=\\hat\\beta_0+\\hat\\beta_1 x^*.$$\n",
    "\n",
    "Les valeurs ajustées sont définies par\n",
    "$$\\hat y_i=f(x_i)=\\hat\\beta_0+\\hat\\beta_1 x_i,$$\n",
    "et les résidus estimés par \n",
    "$$\\hat\\varepsilon_i=y_i-\\hat y_i.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple : Cathédrales\n",
    "\n",
    "Voyons sur les données **cathedral** comment effectuer une régression linéaire simple avec **R**.\n",
    "\n",
    "Importons d'abord les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath <- read.table('cathedral.txt',header=TRUE)\n",
    "names(cath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous aimerions expliquer la hauteur des cathédrales en fonction de la longueur. Calculons d'abord  la corrélation entre variables longueur et hauteur, mesure de la colinéarité entre variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(cath$haut,cath$long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La corrélation est positive, mais pas tout près de 1. Traçons le nuage des points pour vérifier davantage la pertinence d'un modèle de régression linéaire pour nos variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cath$long,cath$haut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimer les paramètres\n",
    "\n",
    "Pour calculer les estimateurs par moindres carrés dans le modèle linéaire, c'est extrêmement facile car  la fonction **lm** (=*linear model*) fait tout. Le plus difficile est de savoir lire la sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.simple <- lm(haut~long, data = cath)\n",
    "summary(reg.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice **Coefficients** comporte pour chaque paramètre (chaque ligne) quatre colonnes : son estimation (colonne **Estimate**), son écart-type estimé (**Std. Error**), la valeur observée de la statistique du test d'hypothèse $H_0:\\beta_k=0$ contre $H_1:\\beta_k\\neq 0$. Enfin, la probabilité critique ou p-valeur (**Pr(>|t|)**) donne, pour la statistique de test sous $H_0$, la probabilité de dépasser la valeur estimée et permet de conclure.\n",
    "\n",
    "Les coefficients $\\beta_0$ et $\\beta_1$ sont estimés par $37.53$ et $0.0874$. Les tests de significativité des coefficients donnent ici des p-valeurs inférieures à $0.001$. Ainsi l'hypothèse nulle de chacun des tests est rejetée au profit de l'hypothèse alternative étant donnée la constante et la variable **long**. La très petite p-valeur  pour la constante indique que la constante (l'intercept) doit apparaître dans le modèle. La très petite p-valeur pour la pente indique une liaison linéaire significative entre la hauteur et la longueur de cathédrale.\n",
    "\n",
    "Le résumé de l'étape d'estimation fait figurer la valeur de l'estimateur $\\hat\\sigma$  de l'écart-type résiduel $\\sigma$, qui vaut ici $11.75$, ainsi que le nombre de degrés de liberté associé $n-2=23$.\n",
    "\n",
    "Nous pouvons consulter la liste des différents résultats de l'objet **reg.simple** et **summary(reg.simple)** avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(reg.simple)\n",
    "names(summary(reg.simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors récupérer les coefficients avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.simple$coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou par la fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(reg.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ajuster un modèle sans la constante, on procède de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.ss.simple <- lm(haut~long-1, data= cath)\n",
    "summary(reg.ss.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer la droite de régression\n",
    "\n",
    "Pour tracer la droite de régression et la superposer au nuage des points, nous pouvons simplement appliquer la commande **abline(reg.simple)**. De plus, on peut rajouter au graphique les valeurs ajustées (disponible dans **reg.simple\\$fitted.values**) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cath$long, cath$haut)\n",
    "abline(reg.simple,col='red')\n",
    "points(cath$long,reg.simple$fitted.values,pch=15,col='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les résidus\n",
    "\n",
    "Les résidus estimés $\\hat\\varepsilon_i$ sont disponibles dans le vecteur **reg.simple\\$residuals**.\n",
    "\n",
    "On obtient les résidus studentisés (par validation croisée) \n",
    "$$t_i^*=\\frac{\\hat\\varepsilon_i}{\\hat \\sigma_{(i)} \\sqrt{1-h_{ii}} },\\qquad i=1,\\dots,n$$\n",
    "par la fonction **rstudent** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residu.simple <- rstudent(reg.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'identifier d'éventuelles valeurs aberrantes dans les données, on utilise la représentation graphique suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- length(cath$haut)\n",
    "plot(1:n,residu.simple,col='blue',xlab='Index',ylab='Résidus studentisés')\n",
    "abline(-2,0)\n",
    "abline(2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand l'échantillon ne contient pas de valeurs aberrantes, 95% des résidus studientisés $t_i^*$ se trouvent dans l'intervalle $[-2,2]$ et les autres 5% proches de ces limites. C'est le cas dans notre exemple puisque un résidu seulement (sur 25) se trouvent à l'extérieur de l'intervalle $[-2,2]$.\n",
    "\n",
    "\n",
    "### Point levier\n",
    "\n",
    "Afin d'identifier des éventuelles observations trop influentes dans le jeu de données, on analyse les poids $h_{ii}$ des observations que l'on obtient par l'instruction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levier <- hatvalues(reg.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compare ces points aux seuils $2p/n$ et $3/pn$ par un graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(1:n, levier, xlab = 'Index', ylab = 'Poids h_ii')\n",
    "p <- reg.simple$rank\n",
    "seuil1 <- 2*p/n\n",
    "seuil2 <- 3*p/n\n",
    "abline(seuil1,0,lty=2)\n",
    "abline(seuil2,0,lty=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe qu'il y a une seule observation qui dépasse les deux seuils, et deux autres au-dessus du  premier seuil.\n",
    "\n",
    "### Entraînement 1\n",
    "Afin de connaître précisément les observations suspectes on peut rajouter des labels dans le graphique. En effet, les individus suspects ont les indices  **ID <- (1:n)[levier>seuil1]**. On peut les mettre en avant dans le graphique par l'instruction\n",
    "**text(ID,levier[ID],ID,col='red',pos=1)**. \n",
    "Essayez-le.\n",
    "\n",
    "On peut analyser ces points davantage en calculant leur distance de Cook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance de Cook\n",
    "\n",
    "La distance de Cook est une autre mesure pour l'influence d'un individu sur l'estimation de $\\beta$. Pour l'observation $i$ elle vaut\n",
    "$$C_i=\\frac{h_{ii}}{p(1-h_{ii})}\\frac{\\hat\\varepsilon_i^2}{\\hat\\sigma^2}.$$\n",
    "Sous **R** on l'obtient par la fonction **cooks.distance** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook <- cooks.distance(reg.simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le seuil critique pour la distance de Cook  à partir duquel on considère que l'observation est trop influente est le quantile $f_{p,n-p}(0.5)$. Une distance de Cook en-dessous de $f_{p,n-p}(0.1)$ est considéré  comme souhaitable. Traçons le graphique pour notre exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(1:n, cook, xlab='Index',ylab='Distance de Cook')\n",
    "s1 <- qf(0.5,p,n-p)\n",
    "s2 <- qf(0.1,p,n-p)\n",
    "abline(s2,0,lty=2)\n",
    "abline(s1,0,lty=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'aucune des distance de Cook dépasse le seuil qui serait préoccupant.\n",
    "\n",
    "### Entraînement 2\n",
    "Comme pour les points leviers, ajouter au graphique les labels des observations suspectes. Comparez avec les valeurs aberrantes et les points leviers.\n",
    "\n",
    "### Intervalles et prévision\n",
    "\n",
    "Ayant une nouvelle observation $x_\\text{new}$, il suffit d'utiliser les estimations pour prévoir la valeur de $Y$ correspondante. Cependant, la valeur prédite est de peu d'intérêt sans l'intervalle de confiance associé. Voyons cela sur un exemple. Nous disposons de la valeur de la longueur d'une nouvelle cathédrale qui est de 312 pieds.\n",
    "\n",
    "Il y a deux façons de calculer la valeur prédite $y^p=\\hat\\beta_0+\\hat\\beta_1*x_\\text{new}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à la main :\n",
    "xnew <- 312\n",
    "val.pred <- coef(reg.simple)[1]+coef(reg.simple)[2]*xnew\n",
    "val.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par la fonction predict :\n",
    "xnew <- data.frame(long=xnew)\n",
    "predict(reg.simple,xnew,interval=\"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **predict** nécessite en argument un **data.frame** avec les mêmes noms de variables explicatives (ici **long**) que les données de départ. La fonction **predict** fournit également l'intervalle de prédiction associée de niveau $0.95$. (L'argument **level** permet de modifier le niveau de confiance de l'intervalle.)\n",
    "\n",
    "La fonction **predict** permet aussi de calculer des intervalles de confiance pour $x^T\\beta$, en utilisant **interval=\"conf\"**. Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(reg.simple,xnew,interval='conf',level=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice \n",
    "\n",
    "Parmi les différentes substances chimiques qui polluent l'air, on compte l'ozone qui a un impact préoccupant sur la santé. Afin de mieux comprendre les conditions météorologiques qui favorisent une teneur élevée d'ozone dans l'air, nous allons analyser un jeu de donnes qui contient 13 variables au total dont la concentration en ozone pendant la journée et des informations sur la température, la nébulosité, le vent, la pluie. Nous disposons de 112 données relevées durant l'été 2001 à Rennes. \n",
    "\n",
    "Dans ce TP nous nous limitons à analyser la concentration maximale en ozone par jour en fonction de la température prévue à midi. Ce sont les variables de nom **maxO3** et **T12** dans le fichier **ozone.txt**. Ainsi, nous considérons le modèle\n",
    "$$\\text{maxO3} = \\beta_0 + \\beta_1*\\text{T12} + \\varepsilon.$$\n",
    "\n",
    "\n",
    "Les autres variables serons analyser au  TP prochain.\n",
    "\n",
    "1. Importer les données. Familiarisez-vous avec les données.\n",
    "2. Tracer le nuage des points et superposer la droite de régression. Quelle est la conculsion du test $H_0:\\beta_k=0$ contre $H_1:\\beta_k\\neq0$ pour chaque $k\\in\\{0,1\\}$\n",
    "? Ajouter au graphique la droite de régression du modèle sans intercept à savoir $\\text{maxO3} =  \\beta*\\text{T12} + \\varepsilon$ et comparer.\n",
    "3. Vérifier par un calcul explicite que les valeurs des estimateurs $\\hat\\beta_0$ et $\\hat\\beta_1$ renvoyées par la fonction **lm** sont exactes. \n",
    "4. Est-ce que le jeu de données contient des valeurs aberrantes ? Retracer le nuage des points en marquant les observations aberrantes.\n",
    "5. Vérifier avec un QQ-plot approprié l'hypothèse gaussienne des résidus $\\varepsilon_i$.\n",
    "6. Comparer par un graphique les résidus estimés $\\hat\\epsilon_i$ aux résidus  standardisés $t_i$ (accessible par la fonction **rstandard**) et aux résidus studentisés $t_i^*$.\n",
    "7. Est-ce que le jeu de données contient des  points leviers ? Marquer les points leviers dans le nuage des points (**T12**,**max03**) (en plus des valeurs aberrantes).\n",
    "8. Analyser la distance de Cook des observations.\n",
    "9. Ajouter à la figure du nuage des points et de la droite de régression  les intervalles de prédiction et de confiance en tout point $x_i$ observé. Comparer les deux intervalles.  Interpréter la forme des bandes de ces intervalles. Interpréter la relation entre intervalle de confiance/prédiction avec les observations atypiques."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
